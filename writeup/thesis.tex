\documentclass[final]{ukthesis}
%you must include these 2 packages.
\usepackage[pdfauthor={Jack Bandy},
            pdftitle={The Title},
            pdfsubject={The Subject},
            pdfkeywords={Some Keywords},
            pdfproducer={Latex with hyperref},
            pdfcreator={latex->dvips->ps2pdf},
            pdfpagemode=UseOutlines,
            bookmarksopen=true,
            letterpaper,
            bookmarksnumbered=true]{hyperref}
\usepackage{memhfixc}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%author data
\author{Jack Bandy}
\title{INTERACTIVE MACHINE LEARNING FOR WORD RECOGNITION ON DAMAGED HANDWRITTEN DOCUMENTS}
\abstract{an abstract}
\advisor{Brent Seales}
\keywords{keywords go here}
\dgs{Miroslaw Truszczynski}
%the title pages
\frontmatter
\maketitle
\begin{acknowledgments}
Acknowledge people/things here
\end{acknowledgments}
\tableofcontents\clearpage
\listoffigures\clearpage
\listoftables\clearpage
%----------------------------------------------
\mainmatter
\chapter{Background}
This is background text.

\section{Related Work}
For several decades, engineers have been developing methods for automated character and word recognition. Generally, these methods take as input some photograph of printed or handwritten text, and produce a transcript of that text as output. This section provides a brief summary of methods which have influenced the course of this research area, focusing on advances in text recognition and handwriting recognition.

It should also be noted that word recognition relates to other text-related tasks. For example, ``word spotting" locates words in an image while ``word recognition" deals with transcribing all words in the document. The methods used in this paper come from a variety of these related tasks, including keyword and character spotting \cite{sharma2015adapting,frinken2012novel}, word recognition \cite{howe2009finding}, and handwriting recognition \cite{fischer2013fast,bluche2013feature}.


\subsection{Handwriting Recognition}
Handwriting recognition can be divided into two major categories, ``online" handwriting recognition and ``offline" handwriting recognition. In the former, software tracks the location of a writing utensil as a user moves it across some surface to produce letters and words. The precise location and motion of the utensil helps reveal the intended writing, however, no such data is available for the historical documents examined in this project.

Thus, more relevant to our project is the task of offline handwriting recognition, in which the input comprises only a picture of the handwriting and no additional information about its creation. A canonical example of the text recognition task is the MNIST dataset \cite{lecun1998mnist}. MNIST comprises grayscale images of individual handwritten digits, 0 to 9, and the objective is to classify each image into the digit written inside of it. Machine learning researchers have been using this task as a benchmark for several decades \cite{bottou1994comparison}, with error rates well below 1\% since 2003 \cite{kussul2004improved}.

Projects using MNIST and similar datasets are premised upon many constraints. For example, a very small vocabulary or character set could be recognized if they were properly aligned and segmented, but as soon as a text ventured outside those constraints (variations on letters, misspelled words, new characters, etc.), the system would falter. Even moderately successful recognition on unconstrained datasets did not exist until the early 2000s.

This changed with the use of hidden Markov Models (HMMs) \cite{marti2001using,bunke2004offline,el1999hmm}. With statistical models built for specific languages, character and word recognition accuracies improved to over 85\% (varying with respect to the test corpus). More impressively, these results came on { \em unconstrained} texts.

While HMMs made the way for unconstrained datasets, many demonstrations were still using the IAM dataset \cite{marti2002iam}, an ad-hoc database for researchers. In other words, {\em truly} unrestricted handwriting recognition was still a long way off even after the strides made by HMMs. Moving forward, a collection of George Washington letters became the de-facto standard. This dataset comprised hundreds of manuscript pages from the Library of Congress, handwritten by George Washington's secretaries.

In the mid-2000s, even state-of-the-art HMM methods yielded word error rates around 50\% on datasets such as the George Washington collection. But around this time, researchers began taking a new angle at the problem. Specifically, projects focused on the process of ``handwriting retrieval,'' rather than attempting complete transcriptions. Such projects allow users to query a dataset of images for a given word, and essentially scans the images for visual matches of that word. For example, \cite{rath2004search} presents a word retrieval system that achieves 63\% mean average precision scores on the George Washington collection.

In \cite{rath2007word}, this approach is formalized as a viable way to generate a searchable index of handwritten papers. Their method of ``wordspotting'' turns the search problem into a clustering problem, where word images that are ``closest'' to the query word are considered matches. Crucially, their approach eliminates the need for recognizing words before retrieval. In other words, matching is done in real-time.

Building upon the success of wordspotting and HMMs, \cite{howe2009finding} takes a step further and first detects {\em characters} in a word, before inferring a word using an ensemble of HMMs. This approach allowed the recognition of words that were never seen during training, and established new standards for the George Washington dataset.

By this time, neural networks were already penetrating the field of handwriting recognition via wordspotting \cite{fernandez2007application}. By 2010, advanced techniques such as bidirectional long short-term memory (BLSTM) were successfully applied to wordspotting \cite{wang2010word} and outperformed other methods. Finally, recurrent neural networks \cite{frinken2012novel} eliminated the need for word segmentation in addition to improving state-of-the-art performance.

It is not surprising that many previous works apply convolutional neural networks (CNNs) on text recognition for handwritten documents \cite{zhong2016spottingnet,sudholt2016phocnet}.


\subsection{Text Recognition}
From a technical standpoint, automatic text recognition is the task of turning an image into the text within the image. ``Text recognition'' here refers to recognizing {\em printed} texts, not handwritten texts.

Object character recognition (OCR) on scanned documents has reached practically perfect performance. However, the fragility of historical documents restricts the kind of scanning required for such performance. Text recognition must therefore occur ``in the wild,'' without alignment assumptions. An important benchmark dataset for this kind of text recognition is Street View Text (SVT) \cite{wang2010word}. SVT was harvested using pictures from Google Street View, and thus contains a heterogeneous collection of word images with a variety of fonts, colors, backgrounds, and more. Despite the variations, word images did not include handwritten characters. 

The SVT dataset was released in 2010, and by 2012, \cite{wang2012end} demonstrated state-of-the-art performance for character recognition and word recognition. The high degree of accuracy was achieved unsupervised feature learning and convolutional neural networks.


Convolutions provide an ideal mechanism for recognizing the shapes of different letters. Others have taken more general approaches to text recognition via CNNs \cite{wang2012end,jaderberg2016reading}, some even eliminating the need for segmentation \cite{rusinol2015efficient}. The network architectures from these papers are, on the whole, restrictively large, whereas both architectures from my experiments were able to run on my laptop.





\section{Motivation}
On the surface, optical character recognition, word recognition, and handwriting recognition appear to be solved problems. As detailed in the previous section, the explosion of machine learning research in recent years has led to drastic improvements in performance on these tasks, and many advancements have even found their way to consumer products. For example, everyday software allows users to search within scans or photographs of printed typeface, and note-taking software can now interpret penmanship that would be indecipherable to many human readers.

However, the process of transcribing ancient documents presents a niche area of text recognition which is not addressed well by standard approaches. Many historical documents, including those reviewed in this project, were meticulously transcribed with legibility comparable to typeface, suggesting that automated transcription would be straightforward. But over time, these documents have incurred damage of all different kinds. The characters originally may have looked like typeface, but after hundreds of years of human handling, physical corrosion, chemical decay, and other processes, reading certain parts of these documents is an arduous task even for skilled textual analysts. For such cases, neither fully human transcription nor fully automated transcription is ideal.

While fully manual transcription is the most accurate solution, it is incredibly time-consuming for larger documents. Moreover, on damaged documents, skilled papyrologists are required to decipher texts. In short, human transcription is often prohibitively costly in terms of time and skilled personnel.

A fully automated transcription algorithm may successfully transcribe certain portions of a historical document, but the damaged portions can distort the algorithm's output to the point of being unusable. This is especially true in cases where letters are literally missing. This is especially true for OCR algorithms which assume constant width, spacing, and more within a document.

An ideal solution would leverage automated transcription for the undamaged portions, and allow a human reader to fill in any gaps. I refer to this as semi-automated transcription. This project presents a pipeline for semi-automated transcription, blending the irreplicable abilities of the human eye with the efficiency and scalability of character recognition algorithms.


\section{Project Components}
There are two main components of the project. The first is a semi-supervised machine learning approach to document transcription, and the second is a word tracing tool for textual scholarship.

\subsection{An Interactive Approach to Automated Transcription}
In this implementation, a user first labels words or letters in the document, generating a small training set for a neural network. A trained neural network will traverse all pages of the document, recognizing occurrences of any word in its training set. If the network finds no words within an area, it documents the location as "unknown" within its output, so that a user studying the transcript can revisit the area and provide a label if possible.

Given a small set of labeled samples, train a neural network in a semi-supervised manner using both labeled and non-labeled data. Once the initial model is trained, use it to create a transcription of the full document. During the transcription process, the model keeps track of difficult word images, prioritizing them for manual labeling afterwards.

\subsection{Word Tracing}
Once the transcription of a document is generated, many scholars wish to trace the outputted text back to the original manuscript image. I implement a simple tool that traces transcript text back to the original input image so that scholars can easily navigate and visualize transcriptions.





\section{Literature Review}
\subsection{2009}
\begin{itemize}
\item Finding words in alphabet soup: Inference on freeform character recognition for historical scripts \cite{howe2009finding}.
\end{itemize}

\subsection{2012}
\begin{itemize}
\item A novel word spotting method based on recurrent neural networks \cite{frinken2012novel}.
\item End-to-end text recognition with convolutional neural networks \cite{wang2012end}.
\end{itemize}

\subsection{2013}
\begin{itemize}
\item Handwritten word recognition using mlp based classifier: A holistic approach \cite{acharyya2013handwritten}.
\item Feature extraction with convolutional neural networks for handwritten word recognition \cite{bluche2013feature}.
\end{itemize}

\subsection{2014}
\begin{itemize}
\item A combined system for text line extraction and handwriting recognition in historical documents \cite{fischer2014combined}
\end{itemize}

\subsection{2015}
\begin{itemize}
\item Efficient segmentation-free keyword spotting in historical document collections \cite{rusinol2015efficient}.
\item Adapting off-the-shelf cnns for word spotting \& recognition \cite{sharma2015adapting}.
\item Segmentation-free handwritten Chinese text recognition with LSTM-RNN \cite{messina2015segmentation}.
\end{itemize}

\subsection{2016}
\begin{itemize}
\item On the Benefits of Convolutional Neural Network Combinations in Offline Handwriting Recognition \cite{suryani2016benefits}.
\item Reading text in the wild with convolutional neural networks \cite{jaderberg2016reading}.
\item PHOCNet: A deep convolutional neural network for word spotting in handwritten documents \cite{sudholt2016phocnet}.
\item SpottingNet: Learning the Similarity of Word Images with Convolutional Neural Network for Word Spotting in Handwritten Historical Documents \cite{zhong2016spottingnet}.
\end{itemize}



\subsection{Surveys}
\begin{itemize}
\item A survey of document image word spotting techniques \cite{giotis2017survey}.

\item A survey on handwritten documents word spotting \cite{ahmed2017survey}.
\end{itemize}
\copyrightnotice





\chapter{Methodology}
\section{Data Input and Preprocessing}
\subsection{Alignment}
\subsection{Segmentation}


\section{Labeling}


\chapter{The First Chapter}
\section{The First Section}
Math goes here.
\begin{figure}[h]
\centering
Here's a figure
\caption{A Simple Figure}
\end{figure}
\begin{table}[h]
\centering
\begin{tabular}{c|c}
Here & is \\
\hline
a & table
\end{tabular}
\caption{A Simple Table}
\end{table}
\copyrightnotice
%-----------------------------------------------
\backmatter
\bibliographystyle{unsrt}   % this means that the order of references
			    % is dtermined by the order in which the
			    % \cite and \nocite commands appear
\bibliography{mybib}  % list here all the bibliographies that
			     % you need. 

\chapter{Vita}
A brief vita goes here.
\end{document}